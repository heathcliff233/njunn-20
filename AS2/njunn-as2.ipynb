{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NN hw02 DANN"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data introduce"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def no_axis_show(img, title='', cmap=None):\n",
        "    fig = plt.imshow(img, interpolation='nearest', cmap=cmap)\n",
        "    fig.axes.get_xaxis().set_visible(False)\n",
        "    fig.axes.get_yaxis().set_visible(False)\n",
        "    plt.title(title)\n",
        "\n",
        "titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'television', 'dog', 'dolphin', 'spider']\n",
        "plt.figure(figsize=(18, 18))\n",
        "for i in range(9):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    fig = no_axis_show(plt.imread(f'./AS2_data/train_data/{i}/{500*i}.bmp'), title=titles[i])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 18))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    fig = no_axis_show(plt.imread(f'./AS2_data/testdata_raw/0/' + str(i).rjust(5, '0') + '.bmp'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-process"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Lambda(lambda x: cv2.Canny(np.array(x), 170, 300)),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15, fill=(0,)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15, fill=(0,)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "source_dataset = ImageFolder('./AS2_data/train_data', transform=source_transform)\n",
        "target_dataset = ImageFolder('./AS2_data/testdata_raw', transform=target_transform)\n",
        "\n",
        "source_dataloader = DataLoader(source_dataset, batch_size=32, shuffle=True)\n",
        "target_dataloader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x).squeeze()\n",
        "        return x\n",
        "\n",
        "class LabelPredictor(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LabelPredictor, self).__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 9),\n",
        "        )\n",
        "\n",
        "    def forward(self, h):\n",
        "        c = self.layer(h)\n",
        "        return c\n",
        "\n",
        "class DomainClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DomainClassifier, self).__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, h):\n",
        "        y = self.layer(h)\n",
        "        return y"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = FeatureExtractor().cuda()\n",
        "label_predictor = LabelPredictor().cuda()\n",
        "domain_classifier = DomainClassifier().cuda()\n",
        "\n",
        "class_criterion = nn.CrossEntropyLoss()\n",
        "domain_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer_F = optim.Adam(feature_extractor.parameters())\n",
        "optimizer_C = optim.Adam(label_predictor.parameters())\n",
        "optimizer_D = optim.Adam(domain_classifier.parameters())"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(source_dataloader, target_dataloader, lamb):\n",
        "    running_D_loss, running_F_loss = 0.0, 0.0\n",
        "    total_hit, total_num = 0.0, 0.0\n",
        "\n",
        "    for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):\n",
        "\n",
        "        source_data = source_data.cuda()\n",
        "        source_label = source_label.cuda()\n",
        "        target_data = target_data.cuda()\n",
        "        \n",
        "        mixed_data = torch.cat([source_data, target_data], dim=0)\n",
        "        domain_label = torch.zeros([source_data.shape[0] + target_data.shape[0], 1]).cuda()\n",
        "        # source data的label为1\n",
        "        domain_label[:source_data.shape[0]] = 1\n",
        "\n",
        "        # Step 1 : train Domain Classifier\n",
        "        feature = feature_extractor(mixed_data)\n",
        "        domain_logits = domain_classifier(feature.detach())\n",
        "        loss = domain_criterion(domain_logits, domain_label)\n",
        "        running_D_loss+= loss.item()\n",
        "        loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Step 2 : train Feature Extractor and Label Predictor\n",
        "        class_logits = label_predictor(feature[:source_data.shape[0]])\n",
        "        domain_logits = domain_classifier(feature)\n",
        "\n",
        "        loss = class_criterion(class_logits, source_label) - lamb * domain_criterion(domain_logits, domain_label)\n",
        "        running_F_loss+= loss.item()\n",
        "        loss.backward()\n",
        "        optimizer_F.step()\n",
        "        optimizer_C.step()\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        optimizer_F.zero_grad()\n",
        "        optimizer_C.zero_grad()\n",
        "\n",
        "        total_hit += torch.sum(torch.argmax(class_logits, dim=1) == source_label).item()\n",
        "        total_num += source_data.shape[0]\n",
        "        print(i, end='\\r')\n",
        "\n",
        "    return running_D_loss / (i+1), running_F_loss / (i+1), total_hit / total_num\n",
        "\n",
        "# train 401 epochs\n",
        "for epoch in range(401):\n",
        "    train_D_loss, train_F_loss, train_acc = train_epoch(source_dataloader, target_dataloader, lamb=0.1)\n",
        "    if epoch % 10 == 0:\n",
        "        fe_name = \"fe\"+str(epoch)+\".pth\"\n",
        "        lp_name = \"lp\"+str(epoch)+\".pth\"\n",
        "        dc_name = \"dc\"+str(epoch)+\".pth\"\n",
        "        torch.save(feature_extractor.state_dict(), fe_name)\n",
        "        torch.save(label_predictor.state_dict(), lp_name)\n",
        "        torch.save(domain_classifier.state_dict(), dc_name)\n",
        "\n",
        "    print('epoch {:>3d}: train D loss: {:6.4f}, train F loss: {:6.4f}, acc {:6.4f}'.format(epoch, train_D_loss, train_F_loss, train_acc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!wget https://box.nju.edu.cn/f/778d174e2ce748658744/?dl=1 -q -O lp400.pth\n",
        "!wget https://box.nju.edu.cn/f/2288da1583df4f33b641/?dl=1 -q -O fe400.pth\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "state_dict1 = torch.load('lp400.pth')\n",
        "state_dict2 = torch.load('fe400.pth')\n",
        "label_predictor.load_state_dict(state_dict1)\n",
        "feature_extractor.load_state_dict(state_dict2)\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "target_dataset = ImageFolder('../input/njunnhw2/0', transform=target_transform)\n",
        "test_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "result = []\n",
        "label_predictor.eval()\n",
        "feature_extractor.eval()\n",
        "for i, (test_data, _) in enumerate(test_dataloader):\n",
        "    test_data = test_data.cuda()\n",
        "\n",
        "    class_logits = label_predictor(feature_extractor(test_data))\n",
        "\n",
        "    x = torch.argmax(class_logits, dim=1).cpu().detach().numpy()\n",
        "    result.append(x)\n",
        "\n",
        "import pandas as pd\n",
        "result = np.concatenate(result)\n",
        "\n",
        "# Generate your submission\n",
        "df = pd.DataFrame({'id': np.arange(0,len(result)), 'label': result})\n",
        "df.to_csv('DaNN_submission.csv',index=False)\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visulization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "feature_extractor.eval()\n",
        "for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):\n",
        "    source_data = source_data.cuda()\n",
        "    target_data = target_data.cuda()\n",
        "    res1 = feature_extractor(source_data).detach().cpu()\n",
        "    res2 = feature_extractor(target_data).detach().cpu()\n",
        "    break\n",
        "X = torch.cat((res1, res2))\n",
        "out = TSNE(n_components=2).fit_transform(X)\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "p1 = out.T[0]\n",
        "p2 = out.T[1]\n",
        "plt.scatter(p1[:32],p2[:32])\n",
        "plt.scatter(p1[32:],p2[32:])\n",
        "plt.show()\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.27.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}